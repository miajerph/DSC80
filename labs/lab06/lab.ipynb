{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ad9ae76",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75560f4",
   "metadata": {},
   "source": [
    "# Lab 6 – APIs and Web Scraping\n",
    "\n",
    "## DSC 80, Spring 2024\n",
    "\n",
    "### Due Date: Wednesday, May 15th at 11:59 PM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29684796",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Welcome to the sixth DSC 80 lab this quarter!\n",
    "\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook, and **you will only submit that `lab.py` file**, not this notebook!\n",
    "\n",
    "Some additional guidelines:\n",
    "- **Unlike in DSC 10, labs will have both public tests and hidden tests.** The bulk of your grade will come from your scores on hidden tests, which you will only see on Gradescope after the assignment deadline.\n",
    "- **Do not change the function names in the `lab.py` file!** The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name. If you changed something you weren't supposed to, you can find the original code in the [course GitHub repository](https://github.com/dsc-courses/dsc80-2024-sp).\n",
    "- Notebooks are nice for testing and experimenting with different implementations before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file, since that's all you're submitting.\n",
    "- You are encouraged to write your own additional helper functions to solve the lab, as long as they also end up in `lab.py`.\n",
    "\n",
    "**To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.** More details on its usage are given at the bottom of this notebook.\n",
    "\n",
    "**Importing code from `lab.py`**:\n",
    "\n",
    "* Below, we import the `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a6aa390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7349f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a468225",
   "metadata": {},
   "source": [
    "If the cell below returns a `ModuleNotFoundError`, please run `!pip install lxml` in a new cell. After `lxml` is succesfully installed, go to `kernel` then restart. Note that you will only need to run `!pip install lxml` once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57e44a42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import bs4\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5befc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dcad96",
   "metadata": {},
   "source": [
    "## Question 1 – Practice with HTML Tags 📎\n",
    "\n",
    "In Question 2, you'll spend plenty of time parsing HTML source code. But before you get your hands dirty trying to extract information from HTML written by other people, it is a good idea to write basic HTML code yourself. This exercise will help you better understand how the code in a `.html` file is structured.\n",
    "\n",
    "For this question, you'll create a very basic `.html` file, named `lab06_1.html`, that satisfies the following conditions:\n",
    "\n",
    "- It must have `<title>` and `<head>` tags.\n",
    "- It must also have `<body>` tags. Within the `<body>` tags, it must have:\n",
    "    - At least two headers.\n",
    "    * At least three images.\n",
    "        - At least one image must be a local file.\n",
    "        - At least one image must be linked to online source.\n",
    "        - At least one image has to have default text when it cannot be displayed.\n",
    "    * At least three references (hyperlinks) to different web pages.\n",
    "    * At least one table with two rows and two columns.\n",
    "    \n",
    "\n",
    "Make sure to save your file as `lab06_1.html`, and save it in the same directory as `lab.py`. **When submitting this homework to Gradescope, make sure to also upload `lab06_1.html` along with the local image that you embedded in your site.** You can upload multiple files to Gradescope at a time.\n",
    "   \n",
    "\n",
    "***Notes***:\n",
    "- You can write and view basic HTML with a Jupyter Notebook, using either a Markdown cell or by using the `IPython.display.HTML` function (which takes in a string of HTML and renders it).\n",
    "- If you write your HTML code within a Jupyter Notebook, you should later copy your code into a text editor and save it with the `.html` extension. You could also write your HTML in a text editor directly.\n",
    "- Be sure to open your final `.html` file in a browser and make sure it looks correct on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd421c-9e21-4ab4-bd3b-b9911e948037",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Mia's Example HTML Page</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Welcome to My Page!</h1>\n",
    "    <h2>Guess what! My birthday is next week.</h2>\n",
    "\n",
    "    <p>Below are some images:</p>\n",
    "    <img src=\"local_image.png\" alt=\"Flier for my Research Project\">\n",
    "    <img src=\"https://cdn-media.theathletic.com/cdn-cgi/image/width=1440%2cformat=auto%2cquality=75/https://cdn-media.theathletic.com/f0XraZOhyUM1_9YbgmKjDwQ2P_1440x960.jpg\" alt=\"Online Image\">\n",
    "    <img src=\"non_existent_image.jpg\" alt=\"Default Text\" onerror=\"this.onerror=null; this.src='default_image.jpg';\">\n",
    "\n",
    "    <p>Here are some references:</p>\n",
    "    <ul>\n",
    "        <li><a href=\"https://www.nytimes.com/athletic/5485410/2024/05/14/caitlin-clark-indiana-fever-wnba-debate/\">Link 1</a></li>\n",
    "        <li><a href=\"https://www.macrumors.com/guide/apple-ring/\">Link 2</a></li>\n",
    "        <li><a href=\"https://www.iamchappellroan.com/tour/\">Link 3</a></li>\n",
    "    </ul>\n",
    "\n",
    "    <p>Below is a table:</p>\n",
    "    <table border=\"1\">\n",
    "        <tr>\n",
    "            <td>Row 1, Column 1</td>\n",
    "            <td>Row 1, Column 2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Row 2, Column 1</td>\n",
    "            <td>Row 2, Column 2</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b413d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't delete this cell!\n",
    "question1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d56ff62",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0117c2",
   "metadata": {},
   "source": [
    "## Question 2 – Scraping an Online Bookstore 📚\n",
    "\n",
    "Browse through the following fake online bookstore: http://books.toscrape.com/. This website is meant for toying with scraping.\n",
    "\n",
    "Your job is to scrape the website, collecting data on all books that have:\n",
    "- **_at least_ a four-star rating**, and\n",
    "- **a price _strictly_ less than £50**, and \n",
    "- **belong to specific categories** (more details below). \n",
    "\n",
    "You will extract the information into a DataFrame that looks like the one below.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>UPC</th>\n",
    "      <th>Product Type</th>\n",
    "      <th>Price (excl. tax)</th>\n",
    "      <th>Price (incl. tax)</th>\n",
    "      <th>Tax</th>\n",
    "      <th>Availability</th>\n",
    "      <th>Number of reviews</th>\n",
    "      <th>Category</th>\n",
    "      <th>Rating</th>\n",
    "      <th>Description</th>\n",
    "      <th>Title</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>e10e1e165dc8be4a</td>\n",
    "      <td>Books</td>\n",
    "      <td>Â£22.60</td>\n",
    "      <td>Â£22.60</td>\n",
    "      <td>Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Default</td>\n",
    "      <td>Four</td>\n",
    "      <td>For readers of Laura Hillenbrand's Seabiscuit...</td>\n",
    "      <td>The Boys in the Boat: Nine Americans...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>c2e46a2ee3b4a322</td>\n",
    "      <td>Books</td>\n",
    "      <td>Â£25.27</td>\n",
    "      <td>Â£25.27</td>\n",
    "      <td>Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Romance</td>\n",
    "      <td>Five</td>\n",
    "      <td>A Michelin two-star chef at twenty-eight, Violette...</td>\n",
    "      <td>Chase Me (Paris Nights #2)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>00bfed9e18bb36f3</td>\n",
    "      <td>Books</td>\n",
    "      <td>Â£34.53</td>\n",
    "      <td>Â£34.53</td>\n",
    "      <td>Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Romance</td>\n",
    "      <td>Five</td>\n",
    "      <td>No matter how busy he keeps himself...</td>\n",
    "      <td>Black Dust</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "To do so, implement the following functions.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `extract_book_links`\n",
    "\n",
    "Complete the implementation of the function `extract_book_links`, which takes in the content of a page that contains book listings as a **string of HTML**, and returns a **list** of URLs of book-specific pages for all books with **_at least_ a four-star rating and a price _strictly_ less than £50**.\n",
    "\n",
    "For this method, the URLs you return should not contain the protocol (i.e. `'https://'`). The protocols should be added back into the URLs when you actually make the requests.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `get_product_info`\n",
    "\n",
    "Complete the implementation of the function `get_product_info`, which takes in the content of a book-specific page as a **string of HTML**, and a list `categories` of book categories. If the input book is in the list of `categories`, `get_product_info` should return a dictionary corresponding to a row in the DataFrame in the image above (where the keys are the column names and the values are the row values). If the input book is not in the list of `categories`, return `None`.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `scrape_books`\n",
    "\n",
    "Finally, put everything together. Complete the implementation of the function `scrape_books`, which takes in an integer `k` and a list `categories` of book categories. `scrape_books` should use `requests` to scrape the first `k` pages of the bookstore and return a DataFrame of only the books that have \n",
    "- **_at least_ a four-star rating**, and\n",
    "- **a price _strictly_ less than £50**, and\n",
    "- **a category that is in the list `categories`**.\n",
    "\n",
    "<br>\n",
    "\n",
    "Some general guidance and tips:\n",
    "\n",
    "- The first page of the bookstore is at http://books.toscrape.com/catalogue/page-1.html. Subsequent pages can be found by clicking the \"Next\" button at the bottom of the page. Look at how the URLs change each time you navigate to a new page; think about how to use f-strings (or some other string formatting technique) to generate these URLs.\n",
    "- Use \"inspect element\" to view the source code of the pages you're trying to scrape. To find a book's category, look at the hyperlinks in the book-specific page for that book.\n",
    "- **`scrape_books` should run in under 180 seconds on the entire bookstore (`k = 50`). `scrape_books` is also the only function that should make `GET` requests; the other two functions parse already-existing HTML.**\n",
    "- When instantiating `bs4.BeautifulSoup` objects, use the optional argument `features='lxml'` to suppress any warnings.\n",
    "- Don't worry about typecasting, i.e. it's fine if `'Number of reviews'` is not stored as type `int`. Also, don't worry if you run into encoding errors in your price columns (as the example DataFrame at the top of this cell contains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e393126a-b5f9-4772-9ddd-f23d00977fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_book_links(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    books = soup.find_all('article', class_='product_pod')\n",
    "    urls = []\n",
    "    for book in books:\n",
    "        rating = book.find('p', class_='star-rating')['class'][1]\n",
    "        price = book.find('p', class_='price_color').get_text()\n",
    "        price = float(price[2:])\n",
    "\n",
    "        if rating in ['Four','Five'] and price < 50:\n",
    "            link = book.find('div', class_='image_container').find('a')['href']\n",
    "            urls.append(link)\n",
    "        \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f098693d-dfcd-4705-b067-b66b507f7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_info(text, categories):\n",
    "    keys = ['UPC', 'Product Type', 'Price (excl. tax)', 'Price (incl. tax)', 'Tax', 'Availability', 'Number of reviews', 'Category', 'Rating', 'Description', 'Title']\n",
    "    soup = BeautifulSoup(text, features=\"lxml\")\n",
    "    categories = [x.lower() for x in categories]\n",
    "\n",
    "    this_cat = soup.find('ul', class_='breadcrumb').find_all('a')[-1].text\n",
    "    if this_cat.lower() not in categories: return None\n",
    "\n",
    "    first_seven = soup.find_all('td') # Get the first seven values for the dict\n",
    "    values = [x.get_text() for x in first_seven]\n",
    "    \n",
    "    values.append(this_cat) # Add category to dictionary\n",
    "    \n",
    "    rating = soup.find('p', class_='star-rating')['class'][1]\n",
    "    values.append(rating)\n",
    "    \n",
    "    description = soup.find('meta', attrs={'name': 'description'})\n",
    "    description = description['content'].strip()\n",
    "    values.append(description) \n",
    "    \n",
    "    title = soup.find('title').get_text().strip().split('|')[0].strip()\n",
    "    values.append(title)\n",
    "    \n",
    "    result = dict(zip(keys, values))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "71b4ad7e-1c6d-428f-9cf5-2b422236732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_books(k, categories):\n",
    "    cols = ['UPC', 'Product Type', 'Price (excl. tax)', 'Price (incl. tax)', 'Tax', 'Availability', 'Number of reviews', 'Category', 'Rating', 'Description', 'Title']\n",
    "    final = pd.DataFrame(columns=cols)\n",
    "    for i in range(1, k+1):\n",
    "        page = requests.get(f'http://books.toscrape.com/catalogue/page-{i}.html')\n",
    "        page_txt = page.text\n",
    "        links = extract_book_links(page_txt)\n",
    "        for book in links:\n",
    "            info = requests.get(f'https://books.toscrape.com/catalogue/{book}')\n",
    "            info_dict = get_product_info(info.text, categories)  \n",
    "            if info_dict == None:\n",
    "                continue\n",
    "            info_df = pd.DataFrame([info_dict])\n",
    "            final = pd.concat([final, info_df])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "085be1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "\n",
    "# public test for extract_book_links \n",
    "extract_book_links_fp = os.path.join('data', 'products.html')\n",
    "extract_book_out = extract_book_links(\n",
    "    open(extract_book_links_fp, encoding='utf-8').read()\n",
    ")\n",
    "extract_book_url = 'scarlet-the-lunar-chronicles-2_218/index.html'\n",
    "\n",
    "# doc tests for get product info\n",
    "get_product_info_fp = os.path.join('data', 'Frankenstein.html')\n",
    "get_product_info_out = get_product_info(\n",
    "    open(get_product_info_fp, encoding='utf-8').read(), ['Default']\n",
    ")\n",
    "\n",
    "# public test for scrape books \n",
    "scrape_books_out = scrape_books(1, ['Mystery'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f07904d7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643fbda7",
   "metadata": {},
   "source": [
    "## Question 3 – API Requests 🤑\n",
    "\n",
    "You trade stocks as a hobby. As an avid `pandas` coder, you decide to calculate statistics of your favorite stocks by pulling data from a public API. The API we will work with can be found at https://financialmodelingprep.com/developer/docs/#Stock-Historical-Price. Specifically, we will use the \"**Daily Chart EOD**\" endpoint (search for it at the linked page).\n",
    "\n",
    "Some relevant definitions:\n",
    "- Ticker: A short code that refers to a stock. For example, Apple's ticker is AAPL and Ford's ticker is F. \n",
    "- Open: The price of a stock at the beginning of a trading day.\n",
    "- Close: The price of a stock at the end of a trading day.\n",
    "- Volume: The total number of shares traded in a day.\n",
    "- Percent change: The difference in price with respect to the original price, as a percentage.\n",
    "\n",
    "To make requests to the aforementioned API, you will need an API key. In order to get one, you will need to make an account at the website. Once you've signed up, you can use the API key that comes with the free plan. It has a limit of 250 requests per day, which should be more than enough. You will have to encode your API key in the URL that you make requests to; see a complete example of such a request at the right side of the [documentation](https://site.financialmodelingprep.com/developer/docs#Stock-Historical-Price).\n",
    "\n",
    "Implement the following two functions.\n",
    "\n",
    "#### `stock_history`\n",
    "\n",
    "Complete the implementation of the function `stock_history`, which takes in a string `ticker` and two integers, `year` and `month`, and returns a DataFrame containing the price history for that stock in that month. Keep all of the attributes that are returned by the API.\n",
    "\n",
    "***Notes***:\n",
    "- Read the API documentation if you get stuck!\n",
    "- [`pd.date_range`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html) takes in two dates and returns a sequence of all dates between the two dates, excluding the right endpoint. How might this be helpful?\n",
    "- The [`requests.get`](https://docs.python-requests.org/en/master/user/quickstart/) function returns a Response object, not the data itself. Use the `json` method on the Response object to extract the relevant JSON, as we did in [Lecture 9](https://dsc80.com/resources/lectures/lec09/lec09-filled.html#Example:-GET-requests-via-requests) (you don't need to `import json` to do this).\n",
    "- You can instantiate a DataFrame using a sequence of dictionaries.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `stock_stats`\n",
    "\n",
    "Create a function `stock_stats` that takes in a DataFrame outputted by `stock_history` and returns a **tuple** of two numbers:\n",
    "1. The percent change of the stock throughout the month as a **percentage**.\n",
    "2. An estimate of the total transaction volume **in billion of dollars** for that month.\n",
    "\n",
    "Both values in the tuple should be **strings** that contain numbers rounded to two decimal places. Add a plus or minus sign in front of the percent change, and make sure that the total transaction volume string ends in a `'B'`.\n",
    "\n",
    "**To compute the percent change**, use the opening price on the first day of the month as the starting price and the closing price on the last day of the month as the ending price.\n",
    "\n",
    "**To compute the total transaction volume**, assume that on any given day, the average price of a share is the midpoint of the high and low price for that day.\n",
    "\n",
    "$$ \\text{Estimated Total Transaction Volume (in dollars)} = \\text{Volume (number of shares traded)} \\times \\text{Average Price} $$\n",
    "\n",
    "For example, suppose there are only three days in March – March 1st, March 2nd, and March 3rd.\n",
    "\n",
    "If BYND (Beyond Meat) opens at \\\\$4 on March 1st and closes at \\\\$5 on March 3rd, its percent change for the month of March is $$\\frac{\\$5-\\$4}{\\$4} = +25.00\\%$$\n",
    "\n",
    "Suppose the high and low prices and volumes of BYND on each day are given below.\n",
    "- March 1st: high \\\\$5, low \\\\$3, volume 500 million (0.5 billion)\n",
    "- March 2nd: high \\\\$5.5, low \\\\$2.5, volume 1 billion\n",
    "- March 3rd: high \\\\$5.25, low \\\\$4, volume 500 million (0.5 billion)\n",
    "\n",
    "Then, the estimated total transaction volume is\n",
    "$$\\frac{\\$5 + \\$3}{2} \\cdot 0.5 B + \\frac{\\$5.5 + \\$2.5}{2} \\cdot 1 B + \\frac{\\$5.25 + \\$4}{2} \\cdot 0.5 B = 8.3125B$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49d749d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_history(ticker, year, month):\n",
    "    start_date = f\"{year}-{month:02d}-01\"\n",
    "    end_date = f\"{year}-{month:02d}-{pd.Period(start_date).days_in_month}\"\n",
    "\n",
    "    url = f\"https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?from={start_date}&to={end_date}&apikey=ATgVbtI43Q4WNnBNUqiuy0VaNjyyqu7o\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    historical_data = data['historical']\n",
    "    df = pd.DataFrame(historical_data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5485e418-2b9c-4b39-8410-fe8491dae9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_stats(history):\n",
    "    open_pr = history.iloc[0]['open']\n",
    "    close_pr = history.iloc[-1]['close']\n",
    "    percent_change = ((close_pr - open_pr) / open_pr) * 100\n",
    "\n",
    "    total_vol = 0\n",
    "    for index, row in history.iterrows():\n",
    "        avg_pr = (row['high'] + row['low']) / 2\n",
    "        daily_vol = row['volume'] * avg_pr\n",
    "        total_vol += daily_vol\n",
    "    total_vol_B = total_vol / 1e9\n",
    "\n",
    "    percent_change = f\"{percent_change:+.2f}%\"\n",
    "    total_vol_B = f\"{total_vol_B:.2f}B\"\n",
    "\n",
    "    return (percent_change, total_vol_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1e34e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "\n",
    "# public test for stock_history\n",
    "history = stock_history('BYND', 2019, 6)\n",
    "\n",
    "# public test for stock_stats\n",
    "stats = stock_stats(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57e86b45",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3 results: All test cases passed!"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e818ba89",
   "metadata": {},
   "source": [
    "## Question 4 – Comment Threads 🧵\n",
    "\n",
    "You regularly browse [Hacker News](https://news.ycombinator.com/) to keep up with the latest news in tech. One link to a Hacker News article is https://news.ycombinator.com/item?id=18344932. Note that this article has 18 comments and has a `storyid` of 18344932.\n",
    "\n",
    "The problem now is that you don't have internet access on your phone during your morning commute to work, so you want to save the interesting stories' comment threads beforehand in a CSV. You find their [API documentation](https://github.com/HackerNews/API) and decide to get to work.\n",
    "\n",
    "Complete the implementation of the function `get_comments`, which takes in a `storyid` and returns a DataFrame of all the comments below the news story. You can ignore \"dead\" comments(you will know them when you see them), as well as \"dead\" comments’ children. **Make sure the order of the comments in your DataFrame is from top to bottom just as you see on the website**. \n",
    "\n",
    "The DataFrame that `get_comments` returns should have 5 columns:\n",
    "1. `'id'`: The unique ID of the comment.\n",
    "2. `'by'`: The author of the comment.\n",
    "3. `'text'`: The actual comment.\n",
    "4. `'parent'`: The unique ID of the comment this comment is replying to.\n",
    "5. `'time'`: When the comment was created (in `pd.Timestamp` format).\n",
    "\n",
    "Some guidance:\n",
    "1. The URL to make requests to is `'https://hacker-news.firebaseio.com/v0/item/{}.json'`, however, the `{}` should be replaced with the ID of the article or page you are trying to access. \n",
    "2. Again, do not `import json` – instead, use the `json` method on the Response object you get back.\n",
    "3. Use depth-first search when traversing the comments tree. You will have to do this manually, since you cannot use Beautiful Soup (which is only for HTML documents, not JSON objects).\n",
    "4. Make sure the length of your returned DataFrame is the same as value for the `'descendants'` key in the response JSON (both of which correspond to the number of comments for the story).\n",
    "5. You are allowed to use loops in this function. You may also want to create at least one helper function.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    You may find <a href=\"https://www.youtube.com/watch?v=uOfwW-onmpc\"><b>this hint video 🎥</b></a> helpful!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02d3c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def format_url(code):\n",
    "    url = f'https://hacker-news.firebaseio.com/v0/item/{code}.json'\n",
    "    return url\n",
    "\n",
    "def get_comment(code):\n",
    "    comment = requests.get(format_url(code)).json()\n",
    "    return comment\n",
    "\n",
    "# class for stack\n",
    "class Stack:\n",
    "    def __init__(self):\n",
    "        self.stack = []\n",
    "\n",
    "    def push(self, item):\n",
    "        self.stack.append(item)\n",
    "\n",
    "    def pop(self):\n",
    "        if not self.is_empty():\n",
    "            return self.stack.pop()\n",
    "        raise IndexError(\"pop from an empty stack\")\n",
    "\n",
    "    def is_empty(self):\n",
    "        return len(self.stack) == 0\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.stack)\n",
    "    \n",
    "def make_df(visited):\n",
    "    keys = ['id', 'by', 'text', 'parent', 'time']\n",
    "    result = pd.DataFrame(columns=keys) \n",
    "    dead_alive = []\n",
    "    for i in visited:\n",
    "        attributes = []\n",
    "        com = get_comment(i)\n",
    "        try: \n",
    "            dead_alive.append(com['dead'])\n",
    "        except KeyError:\n",
    "            dead_alive.append(False)\n",
    "        for i in keys:\n",
    "            try:\n",
    "                attributes.append(com[i])\n",
    "            except KeyError:\n",
    "                attributes.append(np.NaN)\n",
    "\n",
    "        result.loc[len(result)] = attributes\n",
    "    dead_series = pd.Series(dead_alive)\n",
    "    filtered = result[~dead_series].reset_index(drop=True)\n",
    "    \n",
    "    filtered['time'] = filtered['time'].apply(lambda x: datetime.fromtimestamp(x))\n",
    "    return filtered\n",
    "    \n",
    "\n",
    "\n",
    "def get_comments(storyid):\n",
    "    next_up = Stack()\n",
    "    \n",
    "    site = requests.get(format_url(18344932)).json()\n",
    "    reverse_ids = site['kids'][::-1]\n",
    "    # put all the main comments into the next_up stack\n",
    "    for i in reverse_ids:\n",
    "        next_up.push(i)\n",
    "    \n",
    "    # initialize list for visited comments\n",
    "    visited = []\n",
    "\n",
    "    # loop through next_up and continue adding child comments\n",
    "    while not next_up.is_empty():\n",
    "        # move the top comment to the visited list\n",
    "        top = next_up.pop()\n",
    "        visited.append(top)\n",
    "        # get the children of the comment we just popped \n",
    "        try:\n",
    "            for kid in get_comment(top)['kids']:\n",
    "                next_up.push(kid)\n",
    "        # if the comment doesn't have any kids, just continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "    final_df = make_df(visited)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b09d4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't delete this cell, but do run it -- it is needed for the autograder tests\n",
    "comments = get_comments(18344932)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d4553b0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4 results: All test cases passed!"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26529521",
   "metadata": {},
   "source": [
    "## Congratulations! You're done Lab 6! 🏁\n",
    "\n",
    "As a reminder, all of the work you want to submit needs to be in `lab.py`.\n",
    "\n",
    "To ensure that all of the work you want to submit is in `lab.py`, we've included a script named `lab-validation.py` in the lab folder. You shouldn't edit it, but instead, you should call it from the command line (e.g. the Terminal) to test your work.\n",
    "\n",
    "Once you've finished the lab, you should open the command line and run, in the directory for this lab:\n",
    "\n",
    "```\n",
    "python lab-validation.py\n",
    "```\n",
    "\n",
    "**This will run all of the `grader.check` cells that you see in this notebook, but only using the code in `lab.py` – that is, it doesn't look at any of the code in this notebook. If all of your `grader.check` cells pass in this notebook but not all of them pass in your command line with the above command, then you likely have code in your notebook that isn't in your `lab.py`!**\n",
    "\n",
    "You can also use `lab-validation.py` to test individual questions. For instance,\n",
    "\n",
    "```\n",
    "python lab-validation.py q1 q2 q4\n",
    "```\n",
    "\n",
    "will run the `grader.check` cells for Questions 1, 2, and 4 – again, only using the code in `lab.py`. [This video](https://www.loom.com/share/0ea254b85b2745e59322b5e5a8692e91?sid=5acc92e6-0dfe-4555-9b6a-8115b6a52f99) how to use the script as well.\n",
    "\n",
    "Once `python lab-validation.py` shows that you're passing all test cases, you're ready to submit your `lab.py` (and only your `lab.py`) to Gradescope. Once submitting to Gradescope, make sure to stick around until all test cases pass.\n",
    "\n",
    "There is also a call to `grader.check_all()` below in _this_ notebook, but make sure to also follow the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed51168f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17a03f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> os.path.exists('lab06_1.html')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> q01_html = bs4.BeautifulSoup(open(\"lab06_1.html\", encoding='utf-8'), features='lxml')\n>>> len(q01_html.find_all('image')) == 0\nTrue",
         "failure_message": "you should not use the <image> tag to add images",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> extract_book_out[1] == extract_book_url\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(get_product_info_out, dict)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 'Category' in get_product_info_out.keys()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> get_product_info_out['Rating'] == 'Two'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out.shape == (1, 11)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out['Rating'][0] == 'Four'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out['Title'][0] == 'Sharp Objects'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> history.shape == (20, 13)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> history.label.iloc[-1] == 'June 03, 19'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (len(stats[0]), len(stats[1])) == (7, 6)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (float(stats[0][1:-1]) > 30) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> float(stats[1][:-1]) > 1 == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> stats[1][-1] == 'B'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> comments.shape == (18, 5)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> comments.loc[5, 'by'] == 'RobAtticus'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> comments.loc[5, 'time'].day == 31\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
